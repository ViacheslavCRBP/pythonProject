{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ViacheslavCRBP/pythonProject/blob/master/HW_13_GPT_ViacheslavS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZyeU8qnjAw7"
      },
      "source": [
        "# Генерация из GPT"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Взять датасет https://huggingface.co/datasets/merionum/ru_paraphraser решить задачу парафраза\n"
      ],
      "metadata": {
        "id": "52j_kimAtlek"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se6JNcYPjAZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52d88ef0-ad71-42b1-87ba-347c44f7b8eb"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZpCJfoBgODA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d0c9c2-14ce-484b-9121-36a89b4e6085"
      },
      "source": [
        "!wget https://huggingface.co/datasets/merionum/ru_paraphraser"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-26 07:55:17--  https://huggingface.co/datasets/merionum/ru_paraphraser\n",
            "Resolving huggingface.co (huggingface.co)... 18.155.173.45, 18.155.173.126, 18.155.173.64, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.155.173.45|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 314818 (307K) [text/html]\n",
            "Saving to: ‘ru_paraphraser.2’\n",
            "\n",
            "ru_paraphraser.2    100%[===================>] 307.44K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-01-26 07:55:17 (2.70 MB/s) - ‘ru_paraphraser.2’ saved [314818/314818]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia8HOsLMgaua",
        "outputId": "452d5b1b-97f8-49de-dd49-242392b5bd79"
      },
      "source": [
        "with open('tweets.txt', 'r') as f:\n",
        "    tweets = f.read().strip().split('\\n\\n')\n",
        "print(len(tweets))\n",
        "for i in range(3):\n",
        "    print(tweets[i])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n",
            "Соловьев наконец-то вышел на новый уровень - теперь его стали банить и в офлайне\n",
            "Дарим мы тебе бутылку игристого вина. Пить тебе еще рано, но встретиться с ней за некоторые преступления ты уже можешь. ПОЗ-ДРАВ-ЛЯ-ЕМ!\n",
            "Да. Еще очень многие помнят, что такое госплан, как планировалось, талоны на еду, очереди, дефицит, выездные визы. Но спасибо, что напомнил\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxDPUmnJhAuu"
      },
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeVUjitigoj4"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFc42rc8g_wp",
        "outputId": "3fe7fa0d-992f-4013-bac2-4a308da54937"
      },
      "source": [
        "model_name = 'sberbank-ai/rugpt3large_based_on_gpt2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_rb4emjhL1s"
      },
      "source": [
        "import random"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvVleYTChNM8",
        "outputId": "12097a4c-7ab6-4543-e57a-ec7f348af885"
      },
      "source": [
        "sep = '\\n***\\n'\n",
        "\n",
        "prefix = sep.join([''] + random.sample(tweets, k=5) + [''])\n",
        "\n",
        "tokens = tokenizer(prefix, return_tensors='pt')\n",
        "tokens = {k: v.to(model.device) for k, v in tokens.items()}\n",
        "end_token_id = tokenizer.encode('***')[0]\n",
        "print(prefix)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "***\n",
            "Внимание. В России официально появился парк славы Илона Маска\n",
            "***\n",
            "Тонер, картриджи и много-много бумаги\n",
            "***\n",
            "И немножечко зиганул\n",
            "***\n",
            "Да. Еще очень многие помнят, что такое госплан, как планировалось, талоны на еду, очереди, дефицит, выездные визы. Но спасибо, что напомнил\n",
            "***\n",
            "- Скажи что-нибудь сладкое?\n",
            "- Сахар\n",
            "- Не. Еще слаще\n",
            "- Мёд\n",
            "- ЕЩЕ СЛАЩЕ!!!\n",
            "- Бюджет!!!\n",
            "- Вооооот\n",
            "***\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfsS4j48hXki",
        "outputId": "8183c837-6813-4052-c16f-333ef4d62611"
      },
      "source": [
        "size = tokens['input_ids'].shape[1]\n",
        "output = model.generate(\n",
        "    **tokens,\n",
        "    #end_token=end_token_id,\n",
        "    do_sample=False,\n",
        "    max_length=size+128,\n",
        "    repetition_penalty=4.2,\n",
        "    temperature=0.7,\n",
        "    num_beams=3,\n",
        ")\n",
        "decoded = tokenizer.decode(output[0])\n",
        "result = decoded[len(prefix):]\n",
        "print(result)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "А еще у нас в городе есть улица имени космонавта Леонова!\n",
            "***\n",
            "Я не знаю, кто это такой, но он был первым человеком, ступившим на поверхность Луны...\n",
            "***\n",
            "У меня сегодня день рождения - мне исполнился 21 год!\n",
            "***\n",
            "С утра я проснулась с мыслью о том, что надо бы сходить к стоматологу. А потом вспомнила, что уже давно ничего не чистила.<s>\n",
            "Прогулки по Москве \n",
            "\n",
            "1. На ВДНХ:\n",
            "\n",
            "2. У стен Кремля:\n",
            "\n",
            "3. Памятник Минину и Пожарскому:\n",
            "\n",
            "4. Храм Христа\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjWvl0KnhpHJ"
      },
      "source": [
        "# Диалоги"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3iWjkcapklq"
      },
      "source": [
        "Логика та же самая, что и с твитами. Только выбрали разделитель в стиле bash.org"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMp34fnqnPTT"
      },
      "source": [
        "def respond_to_dialog(texts):\n",
        "    prefix = '\\nx:'\n",
        "    for i, t in enumerate(texts):\n",
        "        prefix += t\n",
        "        prefix += '\\nx:' if i % 2 == 1 else '\\ny:'\n",
        "    tokens = tokenizer(prefix, return_tensors='pt')\n",
        "    tokens = {k: v.to(model.device) for k, v in tokens.items()}\n",
        "    end_token_id = tokenizer.encode('\\n')[0]\n",
        "    size = tokens['input_ids'].shape[1]\n",
        "    output = model.generate(\n",
        "        **tokens,\n",
        "        eos_token_id=end_token_id,\n",
        "        do_sample=True,\n",
        "        max_length=size+128,\n",
        "        repetition_penalty=3.2,\n",
        "        temperature=1,\n",
        "        num_beams=3,\n",
        "        length_penalty=0.01,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    decoded = tokenizer.decode(output[0])\n",
        "    result = decoded[len(prefix):]\n",
        "    return result.strip()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3ONplkBnosw",
        "outputId": "c13b3b84-79ea-4510-8b3d-f18428721fcf"
      },
      "source": [
        "seed = input('Начните диалог с ботом любой фразой\\n')\n",
        "history = [seed]\n",
        "while True:\n",
        "    result = respond_to_dialog(history[-10:])\n",
        "    next_sentence = input(result + '\\n')\n",
        "    history.append(result)\n",
        "    history.append(next_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Начните диалог с ботом любой фразой\n",
            "Что же нам теперь делать?\n",
            "А что мы можем сделать?\n",
            "Муравью сможем хвост на лоб приделать?\n",
            "Нет, не сможем.\n",
            "Давай Аляску заберем?\n",
            "Не-а! Муравей - он и в Африке муравей.\n",
            "Давай Аляску и Африку заберем?\n",
            "Ага! А еще лучше Антарктиду...\n",
            "Отличная идея!\n",
            "Ну а дальше что?\n",
            "А дальше Аляску заберем...\n",
            "С чего начнем?\n",
            "С Анкорджа\n",
            "Это как?\n",
            "Запустим туда мигрантов\n",
            "Как это?\n",
            "на лодках\n",
            "Зачем?\n",
            "чтобы забрать Аляску, запустим туда мигрантов на лодках\n",
            "И все?\n",
            "Тупишь?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw70GdX5mh8b"
      },
      "source": [
        "for i in range(10):\n",
        "    print(respond_to_dialog(['Давай поговорим о домашних животных', 'Каких питомцев вы любите?\\n--------',\n",
        "                             'Давай поговорим о машинах', 'Какого цвета твой автомобиль?\\n--------',\n",
        "                             'Давай поговорим о физике']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATxIwIDrmkjk"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}